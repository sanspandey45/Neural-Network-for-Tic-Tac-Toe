# -*- coding: utf-8 -*-
"""NN Tic Tac Toe

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k9fi76_DQa7LQtesk3nRlkjUu0IafdQQ
"""

#####################################################################################################################
#   Assignment 2: Neural Network Analysis
#   This is a starter code in Python 3.6 for a neural network.
#   You need to have numpy and pandas installed before running this code.
#   You need to complete all TODO marked sections.
#   You are free to modify this code in any way you want, but need to mention it
#       in the README file.
#####################################################################################################################
#
#   GOOGLE COLLAB LINK: https://colab.research.google.com/drive/1k9fi76_DQa7LQtesk3nRlkjUu0IafdQQ?usp=sharing
#
#####################################################################################################################

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, log_loss, mean_squared_error, mean_absolute_percentage_error
from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, MinMaxScaler
from matplotlib.lines import Line2D

# Raw URL of the dataset
# url = 'https://raw.githubusercontent.com/sanspandey45/ml-dataset/refs/heads/main/tictactoe.csv'

# Load dataset into a DataFrame
# df = pd.read_csv(url)

# Display the first few rows of DataFrame (original, before preprocessing))
# print(df.head())

class NeuralNet:
    def __init__(self, data_url, header=True):
        self.raw_input = pd.read_csv(data_url)
        # self.processed_data = None
        # self.model = None
        # self.history = {}

    # TODO: Write code for pre-processing the dataset, which would include
    # standardization, normalization,
    #   categorical to numerical, etc
    def preprocess(self):
        # Drop rows with missing values.
        self.raw_input.dropna(inplace=True)

        # Replace 'x', 'o', 'b', 'positive', and 'negativewith numerical values and cast everything as type int.
        self.raw_input = self.raw_input.replace({'x': 1, 'o': 0, 'b': -1, 'positive': 1, 'negative': 0} ).astype(int).infer_objects(copy=False)

        # Separate features and target variable (not needed in this case).
        # feature_columns = self.raw_input.columns[:-1]  # All columns except the last one.
        # target_column = self.raw_input.columns[-1]     # The last column (class).

        # Prepare processed data.
        self.processed_data = self.raw_input

        return 0


    # TODO: Train and evaluate models for all combinations of parameters
    # specified in the init method. We would like to obtain following outputs:
    #   1. Training Accuracy and Error (Loss) for every model
    #   2. Test Accuracy and Error (Loss) for every model
    #   3. History Curve (Plot of Accuracy against training steps) for all
    #       the models in a single plot. The plot should be color coded i.e.
    #       different color for each model
    def train_evaluate(self):
        # print(self.processed_data);
        ncols = len(self.processed_data.columns)
        nrows = len(self.processed_data.index)
        X = self.processed_data.iloc[:, :-1]  # Features
        y = self.processed_data.iloc[:, -1]   # Target

        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(X, y)

        # Standardize the features (not needed in this case)
        # scaler = StandardScaler()
        # X_train = scaler.fit_transform(X_train)
        #X_test = scaler.transform(X_test)

        # Below are the hyperparameters that you need to use for model evaluation
        # You can assume any fixed number of neurons for each hidden layer.

        activations = ['logistic', 'tanh', 'relu']
        learning_rates = [0.01, 0.001]
        max_iterations = [500, 600]  # also known as epochs
        num_hidden_layers = [1, 2]

        # Track metrics for plotting
        results = []

        plt.figure(figsize=(22, 15))
        fig, axs = plt.subplots(1, 2, figsize=(20, 10))
        colors = ['blue', 'orange', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'lightblue', 'cyan', 'magenta', 'lightgreen']
        i = 0;
        j = 0;

        # Create the neural network and keep track of performance metrics
        for activation in activations:
            for lr in learning_rates:
                for max_iter in max_iterations:
                    for num_layers in num_hidden_layers:
                        model = MLPClassifier(hidden_layer_sizes=(12,) * num_layers,
                                              alpha=0.001,
                                              activation=activation,
                                              learning_rate_init=lr,
                                              max_iter=max_iter,
                                              random_state=65)

                        # Fit the model
                        model.fit(X_train, y_train)

                        # Predict
                        train_predictions = model.predict(X_train)
                        test_predictions = model.predict(X_test)

                        # Calculate training and test accuracy
                        train_accuracy = accuracy_score(y_train, train_predictions)
                        test_accuracy = accuracy_score(y_test, test_predictions)

                        # training and test loss
                        train_loss = log_loss(y_train, model.predict_proba(X_train))
                        test_loss = log_loss(y_test, model.predict_proba(X_test))

                        # RMSE
                        train_rmse = (np.sqrt(mean_squared_error(y_train, train_predictions)))
                        test_rmse = (np.sqrt(mean_squared_error(y_test, test_predictions)))

                        # Print results in table
                        results.append((activation, lr, max_iter, num_layers, train_accuracy, test_accuracy, train_loss, test_loss, train_rmse, test_rmse))

                        # Print results in lines
                        # history[activation].append((train_accuracy, test_accuracy, train_loss, test_loss))
                        # print(f"Activation: {activation}, LR: {lr}, Max Iterations: {max_iter} -> "
                        #      f"Train Acc: {train_accuracy:.4f}, Test Acc: {test_accuracy:.4f}, "
                        #      f"Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, "
                        #      f"Train RMSE: {train_rmse: .4f}, Test RMSE: {test_rmse: .4f}, " )

                        # Store accuracy for plotting.
                        epochs = range(len(model.loss_curve_))

                        # Separating into 2 graphs based on max number of iterations.
                        if max_iter == max_iterations[0]:
                            axs[0].plot(epochs, model.loss_curve_, color = colors[i], label=f'{activation}, LR={lr}, Iter={max_iter}, Layers={num_layers}')
                            i = i+1

                        else:
                            axs[1].plot(epochs, model.loss_curve_, color = colors[j], label=f'{activation}, LR={lr}, Iter={max_iter}, Layers={num_layers}')
                            j = j+1


        # PLOT
        results_df = pd.DataFrame(results)
        results_df.columns = ['Activation', 'Learning Rate', 'Max Iterations', 'Hidden Layers', 'Train Accuracy', 'Test Accuracy', 'Train Loss', 'Test Loss', 'Train RMSE', 'Test RMSE']

        # Print the results in a table format
        print();
        print(results_df.to_string(index=False))
        print();

        # Plot the model history
        axs[0].set_xlabel('Epochs')
        axs[0].set_ylabel('Loss')
        axs[0].set_title(f'Training Loss over Epochs for {max_iterations[0]} iterations')
        axs[0].legend()
        axs[0].grid(True)

        axs[1].set_xlabel('Epochs')
        axs[1].set_ylabel('Loss')
        axs[1].set_title(f'Training Loss over Epochs for {max_iterations[1]} iterations')
        axs[1].legend()
        axs[1].grid(True)

        plt.show()

        return 0

if __name__ == "__main__":
    # URL to unpreprocessed Tic Tac Toe dataset from 1991
    url = "https://raw.githubusercontent.com/sanspandey45/ml-dataset/refs/heads/main/tictactoe.csv"

    neural_network = NeuralNet(url)
    neural_network.preprocess()
    neural_network.train_evaluate()
